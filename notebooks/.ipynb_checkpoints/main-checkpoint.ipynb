{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Gender Classification using Random Forest \n",
    "\n",
    "Given a name, we wish to determine the gender of a person. We first discuss data gathering and jump into feature selection. Techniques to chose the right features are also discussed. With 800 features, a performance of 82% is obtained. However, chosing just 4 feature yields an accuracy of up to 75%!  \n",
    "\n",
    "## 1.1 Modules and Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "from nltk.corpus import names #You won't need this, I'll provide the files\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from string import ascii_uppercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a look at how these modules are used in context of our Gender Classification problem.\n",
    "\n",
    "- **collections** : Used to get the Frequency distribution of alphabets in a name. Also used to get Frequency of alphabet pairs and triplets\n",
    "\n",
    "- **names** : We use the Corpus of the Natural Language Processing Toolkit (NLTK) to get our sample names. To Save you the trouble of installing NLTK for a mere dataset, I will include the list of male names _male.txt_ and female names _female.txt_ in the Repository. Here is a sample of 10 names in each file, accessed with or without NLTK. They produce the same output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male name list :  ['Aamir', 'Aaron', 'Abbey', 'Abbie', 'Abbot', 'Abbott', 'Abby', 'Abdel', 'Abdul', 'Abdulkarim']\n",
      "Female name list :  ['Abagael', 'Abagail', 'Abbe', 'Abbey', 'Abbi', 'Abbie', 'Abby', 'Abigael', 'Abigail', 'Abigale']\n"
     ]
    }
   ],
   "source": [
    "#With NLTK\n",
    "male_names =  names.words('male.txt')\n",
    "female_names =  names.words('female.txt')\n",
    "\n",
    "#Print top 10 names in list \n",
    "print(\"Male name list : \", [name for name in male_names[:10]])\n",
    "print(\"Female name list : \", [name for name in female_names[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male name list :  ['Aamir', 'Aaron', 'Abbey', 'Abbie', 'Abbot', 'Abbott', 'Abby', 'Abdel', 'Abdul', 'Abdulkarim']\n",
      "Female name list :  ['Abagael', 'Abagail', 'Abbe', 'Abbey', 'Abbi', 'Abbie', 'Abby', 'Abigael', 'Abigail', 'Abigale']\n"
     ]
    }
   ],
   "source": [
    "#Without NLTK\n",
    "with open('male.txt','r') as min:\n",
    "\tmale_names = [name.strip('\\r\\n') for name in min.readlines()]\n",
    "\n",
    "with open('female.txt','r') as fin:\n",
    "\tfemale_names = [name.strip('\\r\\n') for name in fin.readlines()]\n",
    "\n",
    "#Print top 10 names in list \n",
    "print(\"Male name list : \", [name for name in male_names[:10]])\n",
    "print(\"Female name list : \", [name for name in female_names[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each list will now contain 5,000 male and female names respectively, constructing a dataset of size 10,000.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **random** : Male and Female names should be shuffled for training.\n",
    "- **numpy** : Reshapes testing data from 2D matrix to 1D Vector. This prevents the deprecation warning.\n",
    "- **RandomForestClassifier** : As a part of python's _sklearn_, the Random Forest Classifier is the learning algorithm used for gender classification.\n",
    "- **accuracy_score** : Determines the performance of our classifier.\n",
    "- **ascii_uppercase** : is a string of all uppercase alphabets. The uppercase elements form the _keys_ of our _One-hot Encoding dictionaries_. One-hot Encoding will be explained when encountered in the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ascii_uppercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2   Data Preperation & One Hot Encoding\n",
    "\n",
    "We begin by filtering out names that contain special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get rid of names with non_alphabetic characters\n",
    "male_names = filter(str.isalpha, [str(m) for m in male_names]) #Convert unicode array to string array\n",
    "female_names = filter(str.isalpha, [str(f) for f in female_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all names to upper case. This is done to ensure character frequency distribution is not case sensitive. We provide labels 'M' to signify _male_ and 'F' for _female_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_names = []\n",
    "for name in male_names:\n",
    "\tall_names.append( (name.upper(),'M') )\n",
    "\n",
    "for name in female_names:\n",
    "\tall_names.append( (name.upper(),'F') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot comes from originally from electronics - _one-hot_ meaning there's only 1 _hot_ or _on_ value in this list, while the rest are _cold_. One Hot encoding is used to transform non-numeric variables into corresponding numeric representation that can be better processed by a classifier. Although decision trees like Random Forest used in our case, can perform well without One Hot Encoding, I demonstrate it here so that you can try it with other classifiers if required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create One-hot Encoding dictionary from element string\n",
    "\n",
    "def create_one_hot(eles):\n",
    "\tone_hot = {}\n",
    "\tfor i, l in enumerate(eles):\n",
    "\t\tbits = [0]*len(eles);\t#Every element in the string/list is assigned 0\n",
    "\t\tbits[i] = 1;\t#Only one bit is set to \"ON\"\n",
    "\t\tone_hot[l] = bits \t#Actual assignment is made\n",
    "\treturn one_hot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us transform each character into It's One_Hot vector. Since there are 26 alphabets, each character is transformed into a 26 dimensional one_hot vector as shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  :  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "B  :  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "C  :  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "D  :  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "E  :  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "F  :  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "G  :  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "H  :  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "I  :  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "J  :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "K  :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "L  :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "M  :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "N  :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "O  :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "P  :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Q  :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "R  :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "S  :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "T  :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "U  :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "V  :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "W  :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "X  :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "Y  :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "Z  :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "mono_alpha_hot = create_one_hot(ascii_uppercase)\n",
    "for i, l in enumerate(ascii_uppercase):\n",
    "    print(l, \" : \", mono_alpha_hot[l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create alphabet pairs and perform one_hot encoding. In this case, each alphbet pair is represented as a 676 dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bi_alphabets = [a+b for a in ascii_uppercase for b in ascii_uppercase]\n",
    "bi_alpha_hot = create_one_hot(bi_alphabets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could also create alphabet triplets. However, there are way too many combinations when one hot encoding is performed (26 x 26 x 26 = 17576 possibilities!). So we do not compute their vectors. If you are still interested to see how it runs, try executing the following snippet - similar to alphabet pair creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Crete Alphabet Triplets (Not Recommended)\n",
    "tri_alphabets = [a+b+c for a in ascii_uppercase for b in ascii_uppercase for c in ascii_uppercase]\n",
    "tri_alpha_hot = create_one_hot(tri_alphabets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Choosing Features\n",
    "\n",
    "The list of features initially observed are :\n",
    "- First letter (26 features)\n",
    "- Last Letter  (26 features)\n",
    "- Second Letter (26 features)\n",
    "- Sencond from last Letter (26 features)\n",
    "- Frequency of each alphabet (26 features)\n",
    "- Frequency of alphabet pairs (26 x 26 features)\n",
    "\n",
    "Let us create the list of features for each name sample:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Starts with A', 'Starts with B', 'Starts with C', 'Starts with D', 'Starts with E', 'Starts with F', 'Starts with G', 'Starts with H', 'Starts with I', 'Starts with J']\n"
     ]
    }
   ],
   "source": [
    "feat_names = []\n",
    "feat_names.extend( ['Starts with '+ a for a in  mono_alpha_hot.keys()] )\n",
    "feat_names.extend( ['2nd Character '+ a for a in  mono_alpha_hot.keys()] )\n",
    "feat_names.extend( ['2nd Character from last '+ a for a in  mono_alpha_hot.keys()] )\n",
    "feat_names.extend( ['Ends with '+ a for a in  mono_alpha_hot.keys()] )\n",
    "feat_names.extend( ['Freqency of '+ a for a in list(ascii_uppercase)] )\n",
    "feat_names.extend( ['Contains '+ a for a in list(bi_alphabets)] )\n",
    "\n",
    "#Displaying the first 10 feature names\n",
    "print(feat_names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a method `get_sample` that determines the feature for a given sample `(name, gender)`. The method returns a tuple of:\n",
    "- _features_ : Vector of numeric features\n",
    "- _classification_ : The gender represented as '0' for 'Male' and '1' for 'Female'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_sample(name, gender):\n",
    "\tfeatures = []\n",
    "\tname = name.strip()\n",
    "\t##First Character\n",
    "\tfeatures.extend( mono_alpha_hot[name[0]] )\n",
    "\n",
    "\t##Second Character\n",
    "\tfeatures.extend( mono_alpha_hot[name[1]] )\n",
    "\n",
    "\t##Second Character from Last\n",
    "\tfeatures.extend( mono_alpha_hot[name[-2]] )\n",
    "\n",
    "\t##Last Character\n",
    "\tfeatures.extend( mono_alpha_hot[name[-1]] )\n",
    "\n",
    "\t##Frequency of Alphabets\n",
    "\tfreq = {key : 0 for key in list(ascii_uppercase)} \t#Initialize all keys to 0 for every Alphabet\n",
    "\tupdates = dict(collections.Counter(name))\t#Get the frequency distribution of characters in 'name' \n",
    "\tfreq.update(updates)\t#update the original values of the dictionary\n",
    "\tfeatures.extend( freq.values() ) #Append the list of values\n",
    "\n",
    "\t##Frequency of Alphabet pairs\n",
    "\tfreq = {key : 0 for key in list(bi_alphabets)} #Initialize all keys to 0 for every Alphabet Pair\n",
    "\tupdates = dict(collections.Counter( zip(name, name[1:]) )) #Freq. Distribution in the name in the form (A,B): n\n",
    "\tupdates = {(A+B):n for (A,B),n in zip(updates.keys(),updates.values())}\t#Convert (A,B):n  to dictionary of \"AB\":n.\n",
    "\tfreq.update(updates)\n",
    "\tfeatures.extend( freq.values() ) #Append the list of values\n",
    "\n",
    "\n",
    "\t##Gender Label \n",
    "\t#classification = gender_hot[gender]\n",
    "\tif gender == 'M': \n",
    "\t\tclassification = 0\n",
    "\telse:\n",
    "\t\tclassification = 1\n",
    "\n",
    "\treturn (features, classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method is invoked for every sample encountered and stored into a separate list of tuples `feature_list`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = [get_sample(name, gender) for name, gender in all_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets shuffle the Male and Female names so that we get a well distributed training and testing set. We split the training and testing set such that we have 7,000 training samples and the rest are used for testing. To get an idea of the nature of training and testing data we are dealing with, I will print the shape of their matricies and vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train Features : (7000, 806)\n",
      "Shape of Train Labels : (7000,)\n",
      "Shape of Test Features : (904, 806)\n",
      "Shape of Test Labels : (904,)\n"
     ]
    }
   ],
   "source": [
    "#Shuffle list to make sure Male And Female are mixed well\n",
    "random.shuffle(feature_list)\n",
    "\n",
    "#Split test and train set\n",
    "train_set = feature_list[:7000]\n",
    "test_set = feature_list[7000:]\n",
    "\n",
    "#Conversion to the correct format\n",
    "X_train, y_train = zip(*train_set) #converts list of 2-field tuples to 2 separate lists\n",
    "X_test, y_test = zip(*test_set)\n",
    "\n",
    "print(\"Shape of Train Features :\" , np.array(X_train).shape)\n",
    "print(\"Shape of Train Labels :\" , np.array(y_train).shape)\n",
    "print(\"Shape of Test Features :\" , np.array(X_test).shape)\n",
    "print(\"Shape of Test Labels :\" , np.array(y_test).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we have only 904 test samples and not 3,000. The extra samples had special chracters and were removed in the beginning. We now train a model using the Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=150, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=150, min_samples_split=20)\n",
    "classifier.fit(X_train, y_train)\t#Performs the actual \"training\" phase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a list of predictions `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in range(0,len(X_test)):\n",
    "\ty_pred.extend(classifier.predict(np.array(X_test[i]).reshape(1, -1)))\n",
    "\t#With just \"classifier.predict(X_test[i])\" gives a deprecation warning. \n",
    "\t#We convert it the 2 dimensional array to a 1 D Vector with reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of actual gender classifications `y_test` is used to evaluate the predicted values `y_pred` and a simple accuracy is determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.823008849558\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get up to an 82% accuracy. Not Bad! But this classifier has a ton of features (806 to be precise). Are they all required? Let us determine the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Important Features : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Ends with A', 0.10843337543537425),\n",
       " ('Freqency of A', 0.029289688943486058),\n",
       " ('Ends with E', 0.023185844036222571),\n",
       " ('Ends with D', 0.021376939775492789),\n",
       " ('Ends with O', 0.015102860976895413),\n",
       " ('Ends with I', 0.014996438904921913),\n",
       " ('2nd Character from last O', 0.014863381292715756),\n",
       " ('Freqency of E', 0.014754113415409987),\n",
       " ('Freqency of W', 0.013451043592284198),\n",
       " ('Freqency of I', 0.013073361712530523),\n",
       " ('Ends with R', 0.012533345223687107),\n",
       " ('2nd Character from last N', 0.012280419948120817),\n",
       " ('Ends with S', 0.011763284923750637),\n",
       " ('Ends with N', 0.01155732379227542),\n",
       " ('Contains NA', 0.011084005766727051),\n",
       " ('2nd Character from last A', 0.010774394530821607),\n",
       " ('Freqency of L', 0.0093638230349157928),\n",
       " ('Freqency of O', 0.0093343740485671896),\n",
       " ('Ends with T', 0.0080964778725076975),\n",
       " ('Starts with W', 0.0079101388884845244)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features = sorted(enumerate(classifier.feature_importances_), key=lambda x : x[1], reverse=True)\n",
    "print (\"Most Important Features : \")\n",
    "[(feat_names[idx],prob) for idx, prob in important_features][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Feature Reduction\n",
    "\n",
    "### 1.4.1 One Feature\n",
    "We will rewrite this program using the top features, including them one at a time and observe performance.This is done by redefining the method `get_sample` to include 1 feature. The value is `0` if the name does not end in A, otherwise it takes the value `1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sample(name, gender):\n",
    "\tfeatures = []\n",
    "\tname = name.strip()\n",
    "\t\n",
    "\t##Ends with A\n",
    "\tif name[-1] == 'A':\n",
    "\t\tfeatures.append(1)\n",
    "\telse:\n",
    "\t\tfeatures.append(0)\n",
    "        \n",
    "    ##Gender Label\n",
    "\tif gender == 'M': \n",
    "\t\tclassification = 0\n",
    "\telse:\n",
    "\t\tclassification = 1\n",
    "\n",
    "\treturn (features, classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this miniature definition, we perform the same steps of splitting data into test and train sets, commence training using Random Forest and determine the accuracy of the new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with top feature\n",
      "Epoch  0  :  0.650442477876\n",
      "Epoch  1  :  0.600663716814\n",
      "Epoch  2  :  0.631637168142\n",
      "Epoch  3  :  0.652654867257\n",
      "Epoch  4  :  0.601769911504\n",
      "Epoch  5  :  0.625\n",
      "Epoch  6  :  0.620575221239\n",
      "Epoch  7  :  0.630530973451\n",
      "Epoch  8  :  0.627212389381\n",
      "Epoch  9  :  0.629424778761\n"
     ]
    }
   ],
   "source": [
    "feature_list = [ get_sample(name, gender) for name, gender in all_names]\n",
    "print(\"Accuracy with top feature\")\n",
    "for i in range(10):\n",
    "    #Shuffle list to make sure Male And Female are mixed well\n",
    "    random.shuffle(feature_list)\n",
    "\n",
    "    #Split test and train set\n",
    "    train_set = feature_list[:7000]\n",
    "    test_set = feature_list[7000:]\n",
    "\n",
    "    #Conversion to the correct format\n",
    "    X_train, y_train = zip(*train_set) #converts list of 2-field tuples to 2 separate lists\n",
    "    X_test, y_test = zip(*test_set)\n",
    "\n",
    "    # Random Forest Classifier\n",
    "    classifier = RandomForestClassifier(n_estimators=150, min_samples_split=20)\n",
    "    classifier.fit(X_train, y_train)\t#Performs the actual \"training\" phase\n",
    "\n",
    "    y_pred = []\n",
    "    for j in range(0,len(X_test)):\n",
    "        y_pred.extend(classifier.predict(np.array(X_test[j]).reshape(1, -1)))\n",
    "\n",
    "    print(\"Epoch \", i , \" : \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! By just checking if the last character of the name is 'A', our classifier is able to determine the gender over 60% of the time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 Two Features\n",
    "\n",
    "Let us now include the second most important feature i.e. the frequency of 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sample(name, gender):\n",
    "\tfeatures = []\n",
    "\tname = name.strip()\n",
    "\t\n",
    "\t##Ends with A\n",
    "\tif name[-1] == 'A':\n",
    "\t\tfeatures.append(1)\n",
    "\telse:\n",
    "\t\tfeatures.append(0)\n",
    "        \n",
    "\t##Freq of A\n",
    "\tfeatures.append( name.count('A') )\n",
    "\n",
    "\t##Gender Label     \n",
    "\tif gender == 'M': \n",
    "\t\tclassification = 0\n",
    "\telse:\n",
    "\t\tclassification = 1\n",
    "   \n",
    "\treturn (features, classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We execute it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with top 2 features\n",
      "Epoch  0  :  0.650442477876\n",
      "Epoch  1  :  0.637168141593\n",
      "Epoch  2  :  0.606194690265\n",
      "Epoch  3  :  0.649336283186\n",
      "Epoch  4  :  0.599557522124\n",
      "Epoch  5  :  0.649336283186\n",
      "Epoch  6  :  0.650442477876\n",
      "Epoch  7  :  0.612831858407\n",
      "Epoch  8  :  0.637168141593\n",
      "Epoch  9  :  0.651548672566\n"
     ]
    }
   ],
   "source": [
    "feature_list = [ get_sample(name, gender) for name, gender in all_names]\n",
    "print(\"Accuracy with top 2 features\")\n",
    "for i in range(10):\n",
    "    #Shuffle list to make sure Male And Female are mixed well\n",
    "    random.shuffle(feature_list)\n",
    "\n",
    "    #Split test and train set\n",
    "    train_set = feature_list[:7000]\n",
    "    test_set = feature_list[7000:]\n",
    "\n",
    "    #Conversion to the correct format\n",
    "    X_train, y_train = zip(*train_set) #converts list of 2-field tuples to 2 separate lists\n",
    "    X_test, y_test = zip(*test_set)\n",
    "\n",
    "    # Random Forest Classifier\n",
    "    classifier = RandomForestClassifier(n_estimators=150, min_samples_split=20)\n",
    "    classifier.fit(X_train, y_train)\t#Performs the actual \"training\" phase\n",
    "\n",
    "    y_pred = []\n",
    "    for j in range(0,len(X_test)):\n",
    "        y_pred.extend(classifier.predict(np.array(X_test[j]).reshape(1, -1)))\n",
    "\n",
    "    print(\"Epoch \", i , \" : \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3 Three Features\n",
    "\n",
    "Let us include the feature that checks if a name ends with 'E'. The `get_sample` method is redefined as shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sample(name, gender):\n",
    "\tfeatures = []\n",
    "\tname = name.strip()\n",
    "\t\n",
    "\t##Ends with A\n",
    "\tif name[-1] == 'A':\n",
    "\t\tfeatures.append(1)\n",
    "\telse:\n",
    "\t\tfeatures.append(0)\n",
    "\n",
    "\t##Ends with 'E'\n",
    "\tif name[-1] == 'E':\n",
    "\t\tfeatures.append(1)\n",
    "\telse:\n",
    "\t\tfeatures.append(0)\n",
    "\n",
    "\t#Freq of A\n",
    "\tfeatures.append( name.count('A') )\n",
    "    \n",
    "\t##Gender Label    \n",
    "\tif gender == 'M': \n",
    "\t\tclassification = 0\n",
    "\telse:\n",
    "\t\tclassification = 1\n",
    "\n",
    "\treturn (features, classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with top 3 features\n",
      "Epoch  0  :  0.691371681416\n",
      "Epoch  1  :  0.698008849558\n",
      "Epoch  2  :  0.723451327434\n",
      "Epoch  3  :  0.727876106195\n",
      "Epoch  4  :  0.720132743363\n",
      "Epoch  5  :  0.693584070796\n",
      "Epoch  6  :  0.719026548673\n",
      "Epoch  7  :  0.711283185841\n",
      "Epoch  8  :  0.724557522124\n",
      "Epoch  9  :  0.698008849558\n"
     ]
    }
   ],
   "source": [
    "feature_list = [ get_sample(name, gender) for name, gender in all_names]\n",
    "print(\"Accuracy with top 3 features\")\n",
    "for i in range(10):\n",
    "    #Shuffle list to make sure Male And Female are mixed well\n",
    "    random.shuffle(feature_list)\n",
    "\n",
    "    #Split test and train set\n",
    "    train_set = feature_list[:7000]\n",
    "    test_set = feature_list[7000:]\n",
    "\n",
    "    #Conversion to the correct format\n",
    "    X_train, y_train = zip(*train_set) #converts list of 2-field tuples to 2 separate lists\n",
    "    X_test, y_test = zip(*test_set)\n",
    "\n",
    "    # Random Forest Classifier\n",
    "    classifier = RandomForestClassifier(n_estimators=150, min_samples_split=20)\n",
    "    classifier.fit(X_train, y_train)\t#Performs the actual \"training\" phase\n",
    "\n",
    "    y_pred = []\n",
    "    for j in range(0,len(X_test)):\n",
    "        y_pred.extend(classifier.predict(np.array(X_test[j]).reshape(1, -1)))\n",
    "\n",
    "    print(\"Epoch \", i , \" : \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are getting somewhere! We get a 72% accuracy with the top 3 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.4 Four Features\n",
    "\n",
    "For the last case, lets take the top 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sample(name, gender):\n",
    "\tfeatures = []\n",
    "\tname = name.strip()\n",
    "\t\n",
    "\t##Ends with A\n",
    "\tif name[-1] == 'A':\n",
    "\t\tfeatures.append(1)\n",
    "\telse:\n",
    "\t\tfeatures.append(0)\n",
    "\n",
    "\t##Ends with 'E'\n",
    "\tif name[-1] == 'E':\n",
    "\t\tfeatures.append(1)\n",
    "\telse:\n",
    "\t\tfeatures.append(0)\n",
    "\n",
    "\t#Freq of A\n",
    "\tfeatures.append( name.count('A') )\n",
    "\n",
    "\t##2nd character from end is N\n",
    "\tif name[-2] == 'N':\n",
    "\t\tfeatures.append(1)\n",
    "\telse:\n",
    "\t\tfeatures.append(0)\n",
    "\n",
    "\t##Gender Label \n",
    "\tif gender == 'M': \n",
    "\t\tclassification = 0\n",
    "\telse:\n",
    "\t\tclassification = 1\n",
    "\n",
    "\treturn (features, classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with top 4 features\n",
      "Epoch  0  :  0.713495575221\n",
      "Epoch  1  :  0.699115044248\n",
      "Epoch  2  :  0.71017699115\n",
      "Epoch  3  :  0.721238938053\n",
      "Epoch  4  :  0.728982300885\n",
      "Epoch  5  :  0.728982300885\n",
      "Epoch  6  :  0.724557522124\n",
      "Epoch  7  :  0.701327433628\n",
      "Epoch  8  :  0.70907079646\n",
      "Epoch  9  :  0.74889380531\n"
     ]
    }
   ],
   "source": [
    "feature_list = [ get_sample(name, gender) for name, gender in all_names]\n",
    "print(\"Accuracy with top 4 features\")\n",
    "for i in range(10):\n",
    "    #Shuffle list to make sure Male And Female are mixed well\n",
    "    random.shuffle(feature_list)\n",
    "\n",
    "    #Split test and train set\n",
    "    train_set = feature_list[:7000]\n",
    "    test_set = feature_list[7000:]\n",
    "\n",
    "    #Conversion to the correct format\n",
    "    X_train, y_train = zip(*train_set) #converts list of 2-field tuples to 2 separate lists\n",
    "    X_test, y_test = zip(*test_set)\n",
    "\n",
    "    # Random Forest Classifier\n",
    "    classifier = RandomForestClassifier(n_estimators=150, min_samples_split=20)\n",
    "    classifier.fit(X_train, y_train)\t#Performs the actual \"training\" phase\n",
    "\n",
    "    y_pred = []\n",
    "    for j in range(0,len(X_test)):\n",
    "        y_pred.extend(classifier.predict(np.array(X_test[j]).reshape(1, -1)))\n",
    "\n",
    "    print(\"Epoch \", i , \" : \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Final Thoughts\n",
    "\n",
    "Note that the performance of your gender classification system heavily depends on your dataset. If all your names are from a particular region, say the dataset of only American/Chinese/Indian names, your classifier would perform best at classifying such names."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
